# NOTE: This Dockerfile is based on ROCm 12.1.
# To benchmark on other ROCm versions, search and replace "5.7" and "57".
FROM rocm/dev-ubuntu-22.04:5.7-complete

SHELL ["/bin/bash", "-ec"]

# Step 1. Set up bashrc
RUN grep -v '[ -z "\$PS1" ] && return' ~/.bashrc >/tmp/bashrc && \
    echo "alias conda=micromamba" >>/tmp/bashrc               && \
    mv /tmp/bashrc ~/.bashrc

RUN apt update                                                          && \
    apt install --yes wget curl git vim build-essential openssh-server

RUN bash <(curl -L micro.mamba.pm/install.sh) && source ~/.bashrc       && \
    micromamba create --yes -n python311 -c conda-forge                    \
    python=3.11 pytorch-cpu                                             && \
    micromamba activate python311                                       && \
    pip install --pre --force-reinstall -f https://mlc.ai/wheels           \
                mlc-ai-nightly-rocm57                                      \
                mlc-chat-nightly-rocm57

RUN git clone https://github.com/mlc-ai/mlc-llm.git /mlc_llm             && \
    echo "export PYTHONPATH=\"/mlc_llm/:$PYTHONPATH\"" >> ~/.bashrc
